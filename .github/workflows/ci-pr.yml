# Unique name for this workflow
name: CI on PR

# Definition when the workflow should run
on:
  workflow_dispatch:
  pull_request:
    types: [opened, edited, synchronize, reopened]

# Jobs to be executed
jobs:
  # Formatting and linting only runs on human-submitted PRs
  format-lint-lwc-tests:
    runs-on: ubuntu-latest
    steps:
      # Checkout the source code
      - name: "Checkout source code"
        uses: actions/checkout@v4

      # Cache node_modules to speed up the process
      - name: "Restore node_modules cache"
        id: cache-npm
        uses: actions/cache@v4
        with:
          path: node_modules
          key: npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-${{ env.cache-name }}-
            npm-
      # Install npm dependencies for Prettier and Jest
      - name: "Install npm dependencies"
        if: steps.cache-npm.outputs.cache-hit != 'true'
        run: npm ci

      # Prettier formatting
      - name: "Code formatting verification with Prettier"
        run: npm run prettier:verify

      # Lint LWC / Aura
      - name: "Lint Lightning Web Components / Aura Components"
        run: |
          if find ./force-app/main/default/lwc -mindepth 1 -type d | grep -q .; then
            npm run lint
          else
            echo "No LWC components found. Skipping lint."
          fi

      # LWC unit tests
      - name: "Unit test Lightning Web Components"
        run: npm run test:unit:coverage

      # Upload code coverage data
      - name: "Upload code coverage for LWC to Codecov.io"
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: LWC

  developer-org-test:
    runs-on: ubuntu-latest
    needs: format-lint-lwc-tests
    steps:
      # Apex PMD Validaion
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup PMD
        uses: legetz/setup-pmd@7.1.0
      - name: APEX full scan
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            pmd check --dir ./force-app/main/default/classes/*.cls --rulesets ./ruleset.xml -f text
          else
            echo "No Apex classes found to scan."
          fi

      # Install Salesforce CLI
      - name: "Install Salesforce CLI"
        run: |
          npm install @salesforce/cli --location=global
                   nodeInstallPath=$(npm config get prefix)
                   echo "$nodeInstallPath/bin" >> $GITHUB_PATH
                   sf --version
      # Checkout the source code
      - name: "Checkout source code"
        uses: actions/checkout@v4

      # Store secret for dev hub
      - name: "Populate auth file with DEVHUB_SFDX_URL secret"
        shell: bash
        run: |
          echo ${{ secrets.DEVHUB_SFDX_URL}} > ./DEVHUB_SFDX_URL.txt
          secretFileSize=$(wc -c "./DEVHUB_SFDX_URL.txt" | awk '{print $1}')
          if [ $secretFileSize == 1 ]; then
              echo "Missing DEVHUB_SFDX_URL secret. Is this workflow running on a fork?";
              exit 1;
          fi

      # Update PR description with commit list
      - name: "Update PR description with commit list"
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          sudo apt-get update
          sudo apt-get install -y gh
          PR_NUMBER="${{ github.event.pull_request.number }}"
          COMMITS=$(gh pr view "$PR_NUMBER" --json commits -q '.commits[] | "- ðŸ“ \(.oid[0:7]) \(.messageHeadline)"')
          NEW_DESC="Commits in the PR:
          $COMMITS"
          gh pr edit "$PR_NUMBER" --body "$NEW_DESC"

      # Authenticate dev environment
      - name: "Authenticate Dev environment"
        run: sf org login sfdx-url -f ./DEVHUB_SFDX_URL.txt -a defaultOrg -s

      # Run Apex tests with progress monitoring
      - name: "Run Apex tests with progress monitoring"
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            echo "ðŸš€ Starting Apex Tests execution..."
            
            # Run tests in async mode and get job ID with better error handling
            echo "ðŸ“Š Executing tests with progress monitoring..."
            
            # Create temporary file for command output
            TEMP_OUTPUT=$(mktemp)
            
            # Execute the command without -c (code coverage) first to avoid conflicts
            echo "ðŸŽ¯ Starting test execution..."
            if sf apex test run -r json --target-org defaultOrg > "$TEMP_OUTPUT" 2>&1; then
              # Check if we got JSON response
              TEST_RUN_RESULT=$(cat "$TEMP_OUTPUT")
              
              # Try to parse JSON
              if echo "$TEST_RUN_RESULT" | jq empty 2>/dev/null; then
                echo "ðŸ“‹ Valid JSON received, parsing test run ID..."
                TEST_RUN_ID=$(echo "$TEST_RUN_RESULT" | jq -r '.result.testRunId // null' 2>/dev/null)
              else
                # If no JSON, try to extract test ID from text output
                echo "ðŸ“‹ Text output received, trying to extract test ID..."
                TEST_RUN_ID=$(echo "$TEST_RUN_RESULT" | grep -oE '707[a-zA-Z0-9]{12,15}' | head -1)
                if [ -z "$TEST_RUN_ID" ]; then
                  echo "âš ï¸ Could not extract test ID. Full output:"
                  cat "$TEMP_OUTPUT"
                  TEST_RUN_ID="null"
                else
                  echo "âœ… Extracted test ID from text: $TEST_RUN_ID"
                fi
              fi
            else
              echo "âŒ Command failed. Output:"
              cat "$TEMP_OUTPUT"
              TEST_RUN_ID="null"
            fi
            
            # Clean up temporary file
            rm -f "$TEMP_OUTPUT"
            
            if [ "$TEST_RUN_ID" != "null" ] && [ -n "$TEST_RUN_ID" ]; then
              echo "âœ… Apex Tests started with ID: $TEST_RUN_ID"
              
              # Monitor progress every 30 seconds
              COMPLETED=false
              ATTEMPTS=0
              MAX_ATTEMPTS=40  # 20 minutes max (40 * 30s)
              
              while [ "$COMPLETED" = false ] && [ $ATTEMPTS -lt $MAX_ATTEMPTS ]; do
                sleep 30
                ATTEMPTS=$((ATTEMPTS + 1))
                
                echo "â³ Verifying progress... (Attempt $ATTEMPTS/$MAX_ATTEMPTS - $(date +%H:%M:%S))"
                
                # Get tests current status with better error handling
                RESULT_TEMP=$(mktemp)
                if sf apex test report -i $TEST_RUN_ID -r json --target-org defaultOrg > "$RESULT_TEMP" 2>/dev/null; then
                  RESULT=$(cat "$RESULT_TEMP")
                  rm -f "$RESULT_TEMP"
                else
                  echo "âš ï¸ Could not get test status, retrying..."
                  rm -f "$RESULT_TEMP"
                  continue
                fi
                
                # Validate JSON before parsing
                if echo "$RESULT" | jq empty 2>/dev/null; then
                  STATUS=$(echo "$RESULT" | jq -r '.result.summary.outcome // "Unknown"')
                  TESTS_RAN=$(echo "$RESULT" | jq -r '.result.summary.testsRan // 0')
                  TOTAL_TIME=$(echo "$RESULT" | jq -r '.result.summary.totalTime // "0ms"')
                  
                  echo "ðŸ“ˆ Status: $STATUS | Executed Tests: $TESTS_RAN | Total Time: $TOTAL_TIME"
                  
                  if [ "$STATUS" = "Completed" ] || [ "$STATUS" = "Failed" ]; then
                    COMPLETED=true
                    echo "ðŸŽ¯ Tests completed with status: $STATUS"
                    
                    # Get detailed results
                    PASSING=$(echo "$RESULT" | jq -r '.result.summary.passing // 0')
                    FAILING=$(echo "$RESULT" | jq -r '.result.summary.failing // 0')
                    COVERAGE=$(echo "$RESULT" | jq -r '.result.summary.testRunCoverage // "N/A"')
                    
                    echo "âœ… Success Tests: $PASSING"
                    echo "âŒ Failed Tests: $FAILING"
                    echo "ðŸ“Š Code Coverage: $COVERAGE%"
                    
                    # Get details of failed tests if exist
                    if [ "$FAILING" != "0" ]; then
                      echo ""
                      echo "ðŸ” Details of failed Tests:"
                      echo "$RESULT" | jq -r '.result.tests[]? | select(.Outcome == "Fail") | "âŒ \(.FullName): \(.Message // "Without message")"' 2>/dev/null || echo "Could not parse failed test details"
                    fi
                    
                    echo ""
                    echo "ðŸ“„ Generating detailed report in human-readable format..."
                    sf apex test report -i $TEST_RUN_ID -r human --target-org defaultOrg -d ./tests/apex
                    
                    # Fail the job if tests failed
                    if [ "$STATUS" = "Failed" ]; then
                      echo "ðŸ’¥ Job failed due to failed tests"
                      exit 1
                    fi
                  fi
                else
                  echo "âš ï¸ Invalid JSON response received, retrying in 30 seconds..."
                fi
              done
              
              if [ "$COMPLETED" = false ]; then
                echo "â° Timeout: Tests did not complete within 20 minutes"
                exit 1
              fi
            else
              echo "âŒ Error: Could not get test run ID from command output"
              echo "ðŸ”„ Trying synchronous method as alternative..."
              
              # Use synchronous method with timeout and progress indicators
              echo "â³ Running tests synchronously with progress monitoring..."
              
              timeout 1200 bash -c '
                sf apex test run -c -r human -d ./tests/apex --target-org defaultOrg --wait 20 &
                PID=$!
                
                echo "ðŸ”„ Test execution started (PID: $PID)..."
                
                while kill -0 $PID 2>/dev/null; do
                  echo "â³ Tests in progress... $(date +%H:%M:%S)"
                  sleep 30
                done
                
                wait $PID
                EXIT_CODE=$?
                
                if [ $EXIT_CODE -eq 0 ]; then
                  echo "âœ… All tests completed successfully!"
                else
                  echo "âŒ Some tests failed or there was an error (exit code: $EXIT_CODE)"
                fi
                
                exit $EXIT_CODE
              ' || {
                echo "ðŸ’¥ Tests failed or timed out"
                exit 1
              }
            fi
          else
            echo "â„¹ï¸ No Apex classes found. Skipping tests."
          fi

      # Delete temporary test file that Codecov is unable to parse
      - name: "Delete coverage file (temporary step)"
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            find ./tests/apex -name "test-result-*-codecoverage.json" -delete 2>/dev/null || true
          else
            echo "No Apex classes found to delete coverage file."
          fi

      # Upload code coverage data
      - name: "Upload code coverage for Apex to Codecov.io"
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: Apex
