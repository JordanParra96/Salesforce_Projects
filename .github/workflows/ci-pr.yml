# Unique name for this workflow
name: CI on PR

# Definition when the workflow should run
on:
  workflow_dispatch:
  pull_request:
    types: [opened, edited, synchronize, reopened]

# Jobs to be executed
jobs:
  # Formatting and linting only runs on human-submitted PRs
  format-lint-lwc-tests:
    runs-on: ubuntu-latest
    steps:
      # Checkout the source code
      - name: "Checkout source code"
        uses: actions/checkout@v4

      # Cache node_modules to speed up the process
      - name: "Restore node_modules cache"
        id: cache-npm
        uses: actions/cache@v4
        with:
          path: node_modules
          key: npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            npm-${{ env.cache-name }}-
            npm-
      # Install npm dependencies for Prettier and Jest
      - name: "Install npm dependencies"
        if: steps.cache-npm.outputs.cache-hit != 'true'
        run: npm ci

      # Prettier formatting
      - name: "Code formatting verification with Prettier"
        run: npm run prettier:verify

      # Lint LWC / Aura
      - name: "Lint Lightning Web Components / Aura Components"
        run: |
          if find ./force-app/main/default/lwc -mindepth 1 -type d | grep -q .; then
            npm run lint
          else
            echo "No LWC components found. Skipping lint."
          fi

      # LWC unit tests
      - name: "Unit test Lightning Web Components"
        run: npm run test:unit:coverage

      # Upload code coverage data
      - name: "Upload code coverage for LWC to Codecov.io"
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: LWC

  developer-org-test:
    runs-on: ubuntu-latest
    needs: format-lint-lwc-tests
    steps:
      # Apex PMD Validaion
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup PMD
        uses: legetz/setup-pmd@7.1.0
      - name: APEX full scan
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            pmd check --dir ./force-app/main/default/classes/*.cls --rulesets ./ruleset.xml -f text
          else
            echo "No Apex classes found to scan."
          fi

      # Install Salesforce CLI
      - name: "Install Salesforce CLI"
        run: |
          npm install @salesforce/cli --location=global
                   nodeInstallPath=$(npm config get prefix)
                   echo "$nodeInstallPath/bin" >> $GITHUB_PATH
                   sf --version
      # Checkout the source code
      - name: "Checkout source code"
        uses: actions/checkout@v4

      # Store secret for dev hub
      - name: "Populate auth file with DEVHUB_SFDX_URL secret"
        shell: bash
        run: |
          echo ${{ secrets.DEVHUB_SFDX_URL}} > ./DEVHUB_SFDX_URL.txt
          secretFileSize=$(wc -c "./DEVHUB_SFDX_URL.txt" | awk '{print $1}')
          if [ $secretFileSize == 1 ]; then
              echo "Missing DEVHUB_SFDX_URL secret. Is this workflow running on a fork?";
              exit 1;
          fi

      # Update PR description with commit list
      - name: "Update PR description with commit list"
        if: github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          sudo apt-get update
          sudo apt-get install -y gh
          PR_NUMBER="${{ github.event.pull_request.number }}"
          COMMITS=$(gh pr view "$PR_NUMBER" --json commits -q '.commits[] | "- ðŸ“ \(.oid[0:7]) \(.messageHeadline)"')
          NEW_DESC="Commits in the PR:
          $COMMITS"
          gh pr edit "$PR_NUMBER" --body "$NEW_DESC"

      # Authenticate dev environment
      - name: "Authenticate Dev environment"
        run: sf org login sfdx-url -f ./DEVHUB_SFDX_URL.txt -a defaultOrg -s

      # Run Apex tests with progress monitoring
      - name: "Run Apex tests with progress monitoring"
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            echo "ðŸš€ Starting Apex Tests execution..."
            
            # Run tests in async mode and get job ID with better error handling
            echo "ðŸ“Š Executing tests with progress monitoring..."
            
            # Create temporary file for command output
            TEMP_OUTPUT=$(mktemp)
            
            # Execute the command without -c (code coverage) first to avoid conflicts
            echo "ðŸŽ¯ Starting test execution..."
            if sf apex test run -r json --target-org defaultOrg > "$TEMP_OUTPUT" 2>&1; then
              # Check if we got JSON response
              TEST_RUN_RESULT=$(cat "$TEMP_OUTPUT")
              
              # Try to parse JSON
              if echo "$TEST_RUN_RESULT" | jq empty 2>/dev/null; then
                echo "ðŸ“‹ Valid JSON received, parsing test run ID..."
                TEST_RUN_ID=$(echo "$TEST_RUN_RESULT" | jq -r '.result.testRunId // null' 2>/dev/null)
              else
                # If no JSON, try to extract test ID from text output
                echo "ðŸ“‹ Text output received, trying to extract test ID..."
                TEST_RUN_ID=$(echo "$TEST_RUN_RESULT" | grep -oE '707[a-zA-Z0-9]{12,15}' | head -1)
                if [ -z "$TEST_RUN_ID" ]; then
                  echo "âš ï¸ Could not extract test ID. Full output:"
                  cat "$TEMP_OUTPUT"
                  TEST_RUN_ID="null"
                else
                  echo "âœ… Extracted test ID from text: $TEST_RUN_ID"
                fi
              fi
            else
              echo "âŒ Command failed. Output:"
              cat "$TEMP_OUTPUT"
              TEST_RUN_ID="null"
            fi
            
            # Clean up temporary file
            rm -f "$TEMP_OUTPUT"
            
            if [ "$TEST_RUN_ID" != "null" ] && [ -n "$TEST_RUN_ID" ]; then
              echo "âœ… Apex Tests started with ID: $TEST_RUN_ID"
              
              # Monitor progress every 10 seconds for more responsive feedback
              COMPLETED=false
              ATTEMPTS=0
              MAX_ATTEMPTS=120  # 20 minutes max (120 * 10s)
              
              while [ "$COMPLETED" = false ] && [ $ATTEMPTS -lt $MAX_ATTEMPTS ]; do
                sleep 10
                ATTEMPTS=$((ATTEMPTS + 1))
                
                echo "â³ Verifying progress... (Attempt $ATTEMPTS/$MAX_ATTEMPTS - $(date +%H:%M:%S))"
                
                # Get tests current status using the correct command
                RESULT_TEMP=$(mktemp)
                if sf apex get test --test-run-id "$TEST_RUN_ID" --target-org defaultOrg --json > "$RESULT_TEMP" 2>/dev/null; then
                  RESULT=$(cat "$RESULT_TEMP")
                  rm -f "$RESULT_TEMP"
                  
                  # Debug: show what we're getting
                  echo "ðŸ” Response received, checking status..."
                  
                  # Validate JSON before parsing
                  if echo "$RESULT" | jq empty 2>/dev/null; then
                    STATUS=$(echo "$RESULT" | jq -r '.result.summary.outcome // .result.Outcome // "Unknown"' 2>/dev/null)
                    TESTS_RAN=$(echo "$RESULT" | jq -r '.result.summary.testsRan // .result."Tests Ran" // 0' 2>/dev/null)
                    PASS_RATE=$(echo "$RESULT" | jq -r '.result.summary.passRate // .result."Pass Rate" // "N/A"' 2>/dev/null)
                    
                    echo "ðŸ“ˆ Status: $STATUS | Tests Ran: $TESTS_RAN | Pass Rate: $PASS_RATE"
                    
                    if [ "$STATUS" = "Passed" ] || [ "$STATUS" = "Failed" ] || [ "$STATUS" = "Completed" ]; then
                      COMPLETED=true
                      echo "ðŸŽ¯ Tests completed with status: $STATUS"
                      
                      # Get detailed results
                      PASSING=$(echo "$RESULT" | jq -r '.result.summary.passing // (.result.summary.testsRan // 0)' 2>/dev/null)
                      FAILING=$(echo "$RESULT" | jq -r '.result.summary.failing // 0' 2>/dev/null)
                      FAIL_RATE=$(echo "$RESULT" | jq -r '.result."Fail Rate" // .result.summary.failRate // "0%"' 2>/dev/null)
                      TOTAL_TIME=$(echo "$RESULT" | jq -r '.result."Test Total Time" // .result.summary.totalTime // "N/A"' 2>/dev/null)
                      
                      echo "âœ… Total Tests: $TESTS_RAN"
                      echo "âœ… Pass Rate: $PASS_RATE"
                      echo "âŒ Fail Rate: $FAIL_RATE"
                      echo "â±ï¸ Total Time: $TOTAL_TIME"
                      
                      # Generate final detailed report with code coverage
                      echo ""
                      echo "ðŸ“„ Generating final detailed report with code coverage..."
                      sf apex get test --test-run-id "$TEST_RUN_ID" --target-org defaultOrg --code-coverage --result-format json --output-dir ./tests/apex
                      
                      # Also generate human-readable report
                      echo ""
                      echo "ðŸ“‹ Generating human-readable report..."
                      sf apex get test --test-run-id "$TEST_RUN_ID" --target-org defaultOrg --code-coverage
                      
                      # Fail the job if tests failed
                      if [ "$STATUS" = "Failed" ]; then
                        echo "ðŸ’¥ Job failed due to failed tests"
                        exit 1
                      fi
                    else
                      echo "ðŸ”„ Tests still running (Status: $STATUS)..."
                    fi
                  else
                    echo "âš ï¸ Invalid JSON response received. Raw response:"
                    echo "$RESULT" | head -5
                  fi
                else
                  echo "âš ï¸ Could not get test status using 'sf apex get test', retrying..."
                  rm -f "$RESULT_TEMP"
                fi
              done
              
              if [ "$COMPLETED" = false ]; then
                echo "â° Timeout: Tests did not complete within 20 minutes"
                echo "ðŸ” Final status check..."
                sf apex get test --test-run-id "$TEST_RUN_ID" --target-org defaultOrg || true
                exit 1
              fi
            else
              echo "âŒ Error: Could not get test run ID from command output"
              echo "ðŸ”„ Trying synchronous method as alternative..."
              
              # Use synchronous method with timeout and progress indicators
              echo "â³ Running tests synchronously with progress monitoring..."
              
              # Create tests/apex directory if it doesn't exist
              mkdir -p ./tests/apex
              
              timeout 1200 bash -c '
                sf apex test run -c -r human -d ./tests/apex --target-org defaultOrg --wait 20 &
                PID=$!
                
                echo "ðŸ”„ Test execution started (PID: $PID)..."
                
                while kill -0 $PID 2>/dev/null; do
                  echo "â³ Tests in progress... $(date +%H:%M:%S)"
                  sleep 10
                done
                
                wait $PID
                EXIT_CODE=$?
                
                if [ $EXIT_CODE -eq 0 ]; then
                  echo "âœ… All tests completed successfully!"
                else
                  echo "âŒ Some tests failed or there was an error (exit code: $EXIT_CODE)"
                fi
                
                exit $EXIT_CODE
              ' || {
                echo "ðŸ’¥ Tests failed or timed out"
                exit 1
              }
            fi
          else
            echo "â„¹ï¸ No Apex classes found. Skipping tests."
          fi

      # Delete temporary test file that Codecov is unable to parse
      - name: "Delete coverage file (temporary step)"
        run: |
          if ls ./force-app/main/default/classes/*.cls 1> /dev/null 2>&1; then
            echo "ðŸ§¹ Cleaning up problematic coverage files..."
            find ./tests/apex -name "test-result-*-codecoverage.json" -delete 2>/dev/null || true
            
            echo "ðŸ“ Checking for valid coverage files..."
            ls -la ./tests/apex/ || echo "No tests/apex directory found"
            
            # Look for any coverage files that might exist
            find ./tests/apex -name "*coverage*" -type f 2>/dev/null || echo "No coverage files found"
          else
            echo "No Apex classes found to delete coverage file."
          fi

      # Upload code coverage data
      - name: "Upload code coverage for Apex to Codecov.io"
        if: always()
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          flags: Apex
          directory: ./tests/apex
          fail_ci_if_error: false
          verbose: true
